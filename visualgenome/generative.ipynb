{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path to read output of Extract genome\n",
    "PATH = \"/nas/home/slnagark/Genome/output.tsv\"\n",
    "# path to write into generative.tsv\n",
    "PATH_TSV = \"/nas/home/slnagark/Genome/\"\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    input: output.tsv from extract genome\n",
    "    output: dataframe with image id, region id, subject name, object name, subject synset, object synset, and sentence\n",
    "    \n",
    "    \"\"\"\n",
    "    tsv = open(PATH)\n",
    "    data = pd.read_csv(tsv, sep=\"\\t\")\n",
    "\n",
    "    my_data = data[['image_id','region_id','subject', 'object', 'subject_synset', 'object_synset', 'sentence']].copy()\n",
    "    return my_data\n",
    "\n",
    "def process_sentences(s1, s2, flag):\n",
    "    \"\"\"\n",
    "    input:  s1 - sentence 1\n",
    "            s2 - sentence 2\n",
    "            flag - condition of sentence join\n",
    "    \n",
    "    output: s1 joined with s2\n",
    "    \"\"\"\n",
    "    \n",
    "    if flag == 1:\n",
    "        return s1+\" \"+s2\n",
    "    else:\n",
    "        return s1+\" and \"+s2\n",
    "\n",
    "def get_phraseInfo(my_data):\n",
    "    \"\"\"\n",
    "    Iters through the dataframe to:\n",
    "      1. store a dictionary mapping of subjects to their corresponding sentences.\n",
    "      2. store a dictionary mapping of sentences to their corresponding information.\n",
    "         Information is in the format: (object_synset, subject_synset, object_name, subject_name)\n",
    "    \n",
    "    input: dataframe obtained from load_data()\n",
    "    output: sub2phrase: suject to sentence mappings\n",
    "            phrase2info: sentence to information mappins\n",
    "    \n",
    "    \"\"\"\n",
    "    sub2phrase = defaultdict(list)\n",
    "    phrase2info = defaultdict(list)\n",
    "    \n",
    "    for index, row in my_data.iterrows():\n",
    "\n",
    "        subject_synset = row['subject_synset']\n",
    "        object_synset = row['object_synset']\n",
    "        phrase = row['sentence']\n",
    "        \n",
    "        # add information only if it is not present in the phrase2info dictionary\n",
    "        if (object_synset, subject_synset, row['object'], row['subject']) not in phrase2info[phrase]:\n",
    "            phrase2info[phrase].append((object_synset, subject_synset, row['object'], row['subject']))\n",
    "        \n",
    "        # add new sentences having the same subject in the sub2phrase dictionary \n",
    "        if subject_synset in sub2phrase.keys() and phrase not in sub2phrase[subject_synset]:\n",
    "            sub2phrase[subject_synset].append(phrase)\n",
    "        # add sentences only if they are not present in the sub2phrase dictionary\n",
    "        elif subject_synset not in sub2phrase.keys():\n",
    "            sub2phrase[subject_synset].append(phrase)\n",
    "    return sub2phrase, phrase2info\n",
    "\n",
    "\n",
    "def generate_tsv(sub2phrase, phrase2info):\n",
    "    \"\"\"\n",
    "    Writes to file the unique sentences and their combinations along with concept \n",
    "    strings in the format (s1 subject, s1 object, s2 object)\n",
    "    \n",
    "    input: subject to sentences mappings and phrase to information mappings\n",
    "    output: generative.tsv with columns: Sentence 1, Sentence 2, Combined, Concept Strings, Concept Synsets\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # combi dictionary stores sentence information as follows: \n",
    "    # (s1 object synset, s1 subject synset, s2 object synset, s2 subject synset, s1 object name, s1 subject name, s2 object name, s2 subject name)\n",
    "    combi = defaultdict(list)\n",
    "    \n",
    "    with open(os.path.join(PATH_TSV,'generative.tsv'), 'wt') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t', lineterminator='\\n')\n",
    "        tsv_writer.writerow(['Sentence 1', 'Sentence 2', 'Combined', 'Concept Strings', 'Concept Synsets'])\n",
    "\n",
    "        for index, row in my_data.iterrows():\n",
    "\n",
    "            obj_synset = row['object_synset']\n",
    "            sub_synset = row['subject_synset']         \n",
    "            s1 = row['sentence']                              \n",
    "            \n",
    "            # format of phrases in phrases2info : [object_syns, subject_syns, object name, subject name]\n",
    "\n",
    "            if obj_synset in sub2phrase.keys():\n",
    "                for s2 in sub2phrase[obj_synset]:\n",
    "                    for phrases in phrase2info[s2]:\n",
    "                        # object of s2 != subject of s1 and object of s1 = subject of s2\n",
    "                        if sub_synset != phrases[0] and phrases[1]==obj_synset  :\n",
    "\n",
    "                            combined = process_sentences(s1, s2, 1)\n",
    "\n",
    "                            info = (obj_synset, sub_synset, phrases[0], phrases[1],\n",
    "                                    row['object'], row['subject'], phrases[2], phrases[3])\n",
    "                            \n",
    "                            # to handle repetitive sentences\n",
    "                            if info not in combi[combined]:\n",
    "                                combi[combined].append(info)\n",
    "                                c_string = [info[5], info[4], info[6]] \n",
    "                                c_syns = [info[1], info[0], info[2]] \n",
    "\n",
    "                                tsv_writer.writerow([str(s1), str(s2), str(combined), str(c_string), str(c_syns)])\n",
    "\n",
    "            if sub_synset in sub2phrase.keys():\n",
    "                for s2 in sub2phrase[sub_synset]:\n",
    "                    for phrases in phrase2info[s2]: \n",
    "                        # object of s1 != object of s2 subject of s1 != object of s2 and subhect of s1 = subject of s2\n",
    "                        if obj_synset != phrases[0] and sub_synset != phrases[0] and sub_synset == phrases[1]:\n",
    "\n",
    "                            combined = process_sentences(s1, s2, 2)\n",
    "\n",
    "                            info = (obj_synset, sub_synset,phrases[0],phrases[1],\n",
    "                                                    row['object'],row['subject'] ,phrases[2],phrases[3])\n",
    "                            if info not in combi[combined]:\n",
    "                                combi[combined].append(info)\n",
    "                                c_string = [info[5], info[4], info[6]] \n",
    "                                c_syns = [info[1], info[0], info[2]] \n",
    "\n",
    "                                tsv_writer.writerow([str(s1), str(s2), str(combined), str(c_string), str(c_syns)])\n",
    "        out_file.close()\n",
    "        print(\"File generated successfully!\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    loads data from extract genome and generates generative.tsv file\n",
    "    \"\"\"\n",
    "    my_data = load_data()\n",
    "    sub2phrase, phrase2info = get_phraseInfo(my_data)\n",
    "    generate_tsv(sub2phrase, phrase2info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File generated successfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
