{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall process of Faiss can be divided into three steps:\n",
    "\n",
    "1. Construct training data (expressed in matrix form)\n",
    "2. Select the appropriate Index (the core component of Faiss) and add the training data to the Index.\n",
    "3. Search, that is, search, get the final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file='../output/embeddings/entity_embedding_100.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct training data (expressed in matrix form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 2.96 s, total: 1min 8s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# specify a certain entity embedding tsv file\n",
    "entity_dict = {}        # build a entity name-index bi dictionary\n",
    "entity_embeddings = []  # all the embeddings \n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    for index,line in enumerate(f):\n",
    "        line = line.split('\\t')\n",
    "        entity_name = line[0]\n",
    "        entity_vec =  [ float(i) for i in line[1].split()]\n",
    "        entity_embeddings.append(entity_vec)\n",
    "        entity_dict[entity_name] = index\n",
    "        entity_dict[index] = entity_name\n",
    "        \n",
    "# entity_embeddings=> matrix\n",
    "X = np.array(entity_embeddings).astype(np.float32) # float32\n",
    "dimension = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select the appropriate Index (cos) and add the training data to the Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vectors in the index: 2160968\n"
     ]
    }
   ],
   "source": [
    "# build index (METRIC_INNER_PRODUCT => cos )\n",
    "vec_index = faiss.index_factory(dimension, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "# # normalize all vectors in order to get cos sim \n",
    "faiss.normalize_L2(X)  \n",
    "# add vectors to inde \n",
    "vec_index.add(X) \n",
    "print(f'number of vectors in the index: {vec_index.ntotal}')# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Do some searching \n",
    "\n",
    "\n",
    "normal case:<br>\n",
    "query_set = [[...],[...],[...]]<br>\n",
    "query_mat = np.array([dataSetII]).astype(np.float32)<br>\n",
    "faiss.normalize_L2(query_mat) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first I mimic some query data from the training data\n",
    "query_ent_indices = list(range(0,10)) # first 10 entities\n",
    "query_ent_vecs = [] \n",
    "for i in query_ent_indices:\n",
    "    query_ent_vecs.append(X[i])\n",
    "query_ent_mat = np.array(query_ent_vecs)\n",
    "faiss.normalize_L2(query_ent_mat) \n",
    "query_ent_mat.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity by FAISS:\n",
      " [[1.         0.5627408  0.560689   0.5505445  0.5227501 ]\n",
      " [1.         0.63397956 0.62087405 0.61736274 0.6091253 ]\n",
      " [1.0000001  0.5501119  0.492526   0.4534185  0.45262545]\n",
      " [1.         0.79032516 0.7316501  0.6795417  0.59318507]\n",
      " [1.0000001  0.91658026 0.5612824  0.5433717  0.5390162 ]\n",
      " [1.0000001  0.643106   0.62717223 0.6216079  0.61048394]\n",
      " [1.         0.8696474  0.60579693 0.5931927  0.5783482 ]\n",
      " [1.         0.91595125 0.56046623 0.5452393  0.5428423 ]\n",
      " [1.         0.70229137 0.5333149  0.5329284  0.50476944]\n",
      " [1.         0.5583645  0.50156873 0.49650416 0.4837718 ]]\n",
      "Index by FAISS:\n",
      " [[      0 1373344 1783919 1900104 1067663]\n",
      " [      1  301387 1437270  824150 1862389]\n",
      " [      2 1506143  453263 1231726 1540573]\n",
      " [      3  138325 2021129 1541039  893304]\n",
      " [      4  814217  801442 1711612 1655948]\n",
      " [      5  184425  751910 1939500  152700]\n",
      " [      6 1181189  410574  505696 1375741]\n",
      " [      7 1167554  217863 1002028 1651761]\n",
      " [      8 1805679 1422176 1185354 1636541]\n",
      " [      9  768562  107667 1669901  933578]]\n"
     ]
    }
   ],
   "source": [
    "# after setting topk ,we can do query\n",
    "topk = 5\n",
    "cos_sim, index = vec_index.search(query_ent_mat, topk) # both of them are matrices\n",
    "print(f'Similarity by FAISS:\\n {cos_sim}')\n",
    "print(f'Index by FAISS:\\n {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result \n",
    "res = []\n",
    "for row in range(len(index)):\n",
    "    top5_res = []\n",
    "    for col in range(len(index[0])):\n",
    "        ent_name = entity_dict[index[row,col]]\n",
    "        sim = cos_sim[row,col]\n",
    "        top5_res.append((ent_name,sim))\n",
    "    res.append(top5_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/c/en/saltyback/a', 1.0),\n",
       " ('/c/en/soured', 0.5627408),\n",
       " ('/c/en/cheesed_off/a', 0.560689),\n",
       " ('/c/en/p.o_ed/a', 0.5505445),\n",
       " ('/c/en/torqued_off/a', 0.5227501)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('at:to_see_what_they_are_not_showing_them', 1.0),\n",
       " ('at:personx_keeps_persony_from_seeing', 0.63397956),\n",
       " ('at:to_be_able_to_keep_them_from_seeing_it', 0.62087405),\n",
       " ('at:to_obscure_something', 0.61736274),\n",
       " ('at:to_find_out_what_x_has', 0.6091253)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('/c/en/saltyback/a', 1.0),\n",
       "  ('/c/en/soured', 0.5627408),\n",
       "  ('/c/en/cheesed_off/a', 0.560689),\n",
       "  ('/c/en/p.o_ed/a', 0.5505445),\n",
       "  ('/c/en/torqued_off/a', 0.5227501)],\n",
       " [('at:to_see_what_they_are_not_showing_them', 1.0),\n",
       "  ('at:personx_keeps_persony_from_seeing', 0.63397956),\n",
       "  ('at:to_be_able_to_keep_them_from_seeing_it', 0.62087405),\n",
       "  ('at:to_obscure_something', 0.61736274),\n",
       "  ('at:to_find_out_what_x_has', 0.6091253)],\n",
       " [('/c/en/pot_cheese/n', 1.0000001),\n",
       "  ('/c/en/unaged', 0.5501119),\n",
       "  ('/c/en/ricotta', 0.492526),\n",
       "  ('/c/en/crumbly', 0.4534185),\n",
       "  ('/c/en/sirt/n', 0.45262545)],\n",
       " [('/c/en/set/n/wn/cognition', 1.0),\n",
       "  ('/c/en/bent/n/wn/cognition', 0.79032516),\n",
       "  ('/c/en/hang/n/wn/cognition', 0.7316501),\n",
       "  ('/c/en/knack/n/wn/cognition', 0.6795417),\n",
       "  ('/c/en/shot/a/wn', 0.59318507)],\n",
       " [('/c/en/automatic_drive/n/wn/artifact', 1.0000001),\n",
       "  ('/c/en/automatic_transmission/n/wn/artifact', 0.91658026),\n",
       "  ('/c/en/pickeerers/n', 0.5612824),\n",
       "  ('/c/en/gruners/n', 0.5433717),\n",
       "  ('/c/en/rasheed/n', 0.5390162)],\n",
       " [('at:get_money_out_of_the_bank', 1.0000001),\n",
       "  ('at:purchases_clothes', 0.643106),\n",
       "  ('at:put_away_items', 0.62717223),\n",
       "  ('at:goes_to_dressing_room', 0.6216079),\n",
       "  ('at:personx_is_shopping_at_the_mall', 0.61048394)],\n",
       " [('/c/en/emblazers/n', 1.0),\n",
       "  ('/c/en/emblazer', 0.8696474),\n",
       "  ('/c/en/lolapalooza', 0.60579693),\n",
       "  ('/c/en/palempores/n', 0.5931927),\n",
       "  ('/c/en/lolapaloozas/n', 0.5783482)],\n",
       " [('/c/en/rubber_disk', 1.0),\n",
       "  ('/c/en/rubber_disks', 0.91595125),\n",
       "  ('/c/en/lamuvidine/n', 0.56046623),\n",
       "  ('/c/en/aspidodiadematid/n', 0.5452393),\n",
       "  ('Q17771376', 0.5428423)],\n",
       " [('/c/en/nonshadowed', 1.0),\n",
       "  ('/c/en/shadowed', 0.70229137),\n",
       "  ('/c/en/devines/n', 0.5333149),\n",
       "  ('/c/en/unshadowed', 0.5329284),\n",
       "  ('/c/en/devine', 0.50476944)],\n",
       " [('/c/en/splayfoot/n', 1.0),\n",
       "  ('/c/en/splayfooted', 0.5583645),\n",
       "  ('/c/en/hydrobiids/n', 0.50156873),\n",
       "  ('/c/en/hydrobiid', 0.49650416),\n",
       "  ('/c/en/varus/n', 0.4837718)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcs",
   "language": "python",
   "name": "mcs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
