{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "kgtk_wn_file=\"kgtk_wordnet.tsv\"\n",
    "kgtk_cn_file=\"kgtk_conceptnet.tsv\"\n",
    "\n",
    "# output files\n",
    "wn_gold_file=\"wn_gold_all.tsv\"\n",
    "wn_gold_200_file=\"wn_gold_200.tsv\"\n",
    "wn_mrs_prediction_file=\"wn_MRS_200.tsv\"\n",
    "wn_mfs_prediction_file=\"wn_MFS_200.tsv\"\n",
    "wn_stb_prediction_file=\"wn_STB_200.tsv\"\n",
    "wn_str_prediction_file=\"wn_STR_200.tsv\"\n",
    "cn_test_1k_file=\"cn_test_1k.tsv\"\n",
    "cn_prediction_file=\"cn_predict_1k.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate wn_gold_all.tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head, lines = load_file(kgtk_wn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the head look like\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_gold_all = generate_gold_file(lines)\n",
    "# example of new dataset\n",
    "wn_gold_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write gold data into file\n",
    "write_gold(wn_gold_file,wn_gold_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(wn_gold_all):\n",
    "    # obtain the dsitribution of each label\n",
    "    # output: {label1-> str: num->integer}\n",
    "    distri = dict()\n",
    "    for line in wn_gold_all:\n",
    "        node1_label = line[0]\n",
    "        node2_label = line[2]\n",
    "        node1_id = line[3]\n",
    "        node2_id = line[4]\n",
    "        temp1 = distri.get(node1_label,set())\n",
    "        temp1.add(node1_id)\n",
    "        temp2 = distri.get(node2_label,set())\n",
    "        temp2.add(node2_id)\n",
    "        distri[node1_label] = temp1\n",
    "        distri[node2_label] = temp2\n",
    "    \n",
    "    for item in distri:\n",
    "        distri[item] = len(distri[item])\n",
    "    return distri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distri = distribution(wn_gold_all)\n",
    "plt.hist(distri.values(),log=True)\n",
    "print(\"mean ambiguity of label:\", sum(distri.values())/len(distri), \"size of records:\", len(wn_gold_all), \"num of distinct labels:\", len(distri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random pick 200 records\n",
    "wn_gold_200 = random.choices(wn_gold_all, k=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write gold data into file\n",
    "write_gold(wn_gold_200_file,wn_gold_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get synsets\n",
    "**Detail Function is in util.py \"get synsets part\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the sysets of one phrase by WordNet interface\n",
    "generate_candidates(\"far cry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRS(wn_gold):\n",
    "    # Random Baseline calculation\n",
    "    wn_predict = []\n",
    "    for line in wn_gold:\n",
    "        label1  = line[0]\n",
    "        label2 = line[2]\n",
    "        relationship = line[1]\n",
    "        \n",
    "        candidates1 = generate_candidates(label1)\n",
    "        candidates2 = generate_candidates(label2)\n",
    "        \n",
    "        if candidates1:\n",
    "            node1_id = random.choice(candidates1)\n",
    "        else:\n",
    "            #_ = label1\n",
    "            node1_id = \"\"\n",
    "        \n",
    "        if candidates2:\n",
    "            node2_id = random.choice(candidates2)\n",
    "        else:\n",
    "            #_ = label2\n",
    "            node2_id = \"\"\n",
    "        \n",
    "        #print(node2_id)\n",
    "        wn_predict.append([label1, relationship, label2, node1_id, node2_id])\n",
    "        \n",
    "    return wn_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_predict_200 = MRS(wn_gold_200)\n",
    "wn_predict_200[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(wn_predict,wn_gold):\n",
    "    # check accracy of prediction\n",
    "    # accuracy1: if label is correct, true positive +1\n",
    "    # accuracy2: iff two labels in one record are correct (record is correct), true positive +1\n",
    "    correct1 = 0\n",
    "    correct2 = 0\n",
    "    for predict, actual in zip(wn_predict, wn_gold):\n",
    "        #print(predict, actual)\n",
    "        judge = [synset2str(predict[3]) == actual[3],synset2str(predict[4]) == actual[4]]\n",
    "        #print(predict[3],actual[3])\n",
    "        if judge[0]:\n",
    "            correct1 += 1\n",
    "            \n",
    "        if judge[1]:\n",
    "            correct1 += 1\n",
    "            \n",
    "        if all(judge):\n",
    "            correct2 += 1\n",
    "            \n",
    "    return correct1/(len(wn_predict)*2), correct2/len(wn_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_prediction(wn_mrs_prediction_file, wn_predict_200)\n",
    "accuracy1, accuracy2 = validation(wn_predict_200,wn_gold_200)\n",
    "accuracy1, accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFS(wn_gold):\n",
    "    # Frequent Baseline Calculation\n",
    "    wn_predict = []\n",
    "    for line in wn_gold:\n",
    "        label1  = line[0]\n",
    "        label2 = line[2]\n",
    "        relationship = line[1]\n",
    "        \n",
    "        candidates1 = generate_candidates(label1)\n",
    "        candidates2 = generate_candidates(label2)\n",
    "        \n",
    "        if candidates1:\n",
    "            node1_id = candidates1[0]\n",
    "        else:\n",
    "            #print(label1)\n",
    "            #_ = label1\n",
    "            node1_id = \"\"\n",
    "        \n",
    "        if candidates2:\n",
    "            node2_id = candidates2[0]\n",
    "        else:\n",
    "            #print(label2)\n",
    "            #_ = label2\n",
    "            node2_id = \"\"\n",
    "        \n",
    "        #print(node2_id)\n",
    "        wn_predict.append([label1, relationship, label2, node1_id, node2_id])\n",
    "        \n",
    "    return wn_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_predict_200 = MFS(wn_gold_200)\n",
    "wn_predict_200[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_prediction(wn_mfs_prediction_file, wn_predict_200)\n",
    "accuracy1, accuracy2 = validation(wn_predict_200,wn_gold_200)\n",
    "accuracy1, accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence-transformer-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_STB = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the relationship\n",
    "relationships = set()\n",
    "\n",
    "for line in wn_gold_all:\n",
    "    relationships.add(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2sentence = {'/r/IsA':\"is a\", '/r/MadeOf': \"is made of\",'/r/PartOf':\"is part of\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(wn_gold, model = None, label_embeddings = None, word2sentence = None):\n",
    "    # use sentences embedding to find most similar candit\n",
    "    wn_predict = []\n",
    "    sents_combine = []\n",
    "    \n",
    "    for line in wn_gold:\n",
    "        sentence = line_sentence(line, word2sentence)\n",
    "        sents_combine.append(sentence)\n",
    "    sents_embedding = model.encode(sents_combine)\n",
    "    \n",
    "    for line,sent_embedding in zip(wn_gold,sents_embedding):\n",
    "        label1 = line[0]\n",
    "        label2 = line[2]\n",
    "\n",
    "        #obtain the max similar item for label1\n",
    "        node_id1 = max_candidate(label1,sent_embedding,label_embeddings) \n",
    "        \n",
    "        #obtain the max similar item for label2\n",
    "        node_id2 = max_candidate(label2,sent_embedding,label_embeddings) \n",
    "                \n",
    "        wn_predict.append([label1, line[1], label2,node_id1,node_id2])\n",
    "        \n",
    "    return wn_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_embeddings = candidates_embeddings(wn_gold_200, model_STB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_predict_200 = sentence_embedding(wn_gold_200, model = model_STB, label_embeddings = label_embeddings, word2sentence = word2sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_prediction(wn_stb_prediction_file, wn_predict_200)\n",
    "accuracy1, accuracy2 = validation(wn_predict_200,wn_gold_200)\n",
    "accuracy1, accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence-transformer-roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_STR = SentenceTransformer('bert-large-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_embeddings = candidates_embeddings(wn_gold_200, model_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_predict_200 = sentence_embedding(wn_gold_200, model = model_STR, label_embeddings = label_embeddings, word2sentence = word2sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_prediction(wn_str_prediction_file, wn_predict_200)\n",
    "accuracy1, accuracy2 = validation(wn_predict_200,wn_gold_200)\n",
    "accuracy1, accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_MRS = []\n",
    "accuracy_MFS = []\n",
    "accuracy_STB = []\n",
    "accuracy_STR = []\n",
    "n=10\n",
    "for i in range(n):\n",
    "    print(\"\\r\",i, end=\"\")\n",
    "    wn_gold_200 = random.choices(wn_gold_all, k=200)\n",
    "    wn_predict_200 = MRS(wn_gold_200)\n",
    "    accuracy1, accuracy2 = validation(wn_predict_200,wn_gold_200)\n",
    "    accuracy_MRS.append(accuracy1)\n",
    "    \n",
    "    wn_predict_200 = MFS(wn_gold_200)\n",
    "    accuracy1, accuracy2 = validation(wn_predict_200,wn_gold_200)\n",
    "    accuracy_MFS.append(accuracy1)\n",
    "    \n",
    "    label_embeddings = candidates_embeddings(wn_gold_200, model_STB)\n",
    "    wn_predict_200 = sentence_embedding(wn_gold_200, model = model_STB, label_embeddings = label_embeddings, word2sentence = word2sentence)\n",
    "    accuracy1, accuracy2 = validation(wn_predict_200,wn_gold_200)\n",
    "    accuracy_STB.append(accuracy1)\n",
    "    \n",
    "    label_embeddings = candidates_embeddings(wn_gold_200, model_STR)\n",
    "    wn_predict_200 = sentence_embedding(wn_gold_200, model = model_STR, label_embeddings = label_embeddings, word2sentence = word2sentence)\n",
    "    accuracy1, accuracy2 = validation(wn_predict_200,wn_gold_200)\n",
    "    accuracy_STR.append(accuracy1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "x_axis = range(n)\n",
    "plt.plot(x_axis, accuracy_MRS, color='green', label='MRS')\n",
    "plt.plot(x_axis, accuracy_MFS, color='red', label='MFS')\n",
    "plt.plot(x_axis, accuracy_STB,  color='skyblue', label='STB')\n",
    "plt.plot(x_axis, accuracy_STR, color='blue', label='STR')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('iteration times')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head, lines = load_file(kgtk_cn_file)\n",
    "lines_1k = random.choices(lines, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_test_1k = generate_gold_file(lines_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_predict_1k = MFS(cn_test_1k)\n",
    "# write prediction\n",
    "write_prediction(cn_prediction_file, cn_predict_1k)\n",
    "cn_predict_1k[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Mehotd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_synset_prob(cn_predict_1k):\n",
    "    #prob 1: no synset for label\n",
    "    #prob 2: no synset for record\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    for record in cn_predict_1k:\n",
    "        judge = [synset2str(record[3]) == \"wn:\",synset2str(record[4]) == \"wn:\"]\n",
    "        \n",
    "        if judge[0]:\n",
    "            count1 += 1\n",
    "            \n",
    "        if judge[1]:\n",
    "            count1 += 1\n",
    "            \n",
    "        if any(judge):\n",
    "            count2 += 1\n",
    "            \n",
    "    return count1,count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing probability\n",
    "coun1,count2 = no_synset_count(cn_predict_1k)\n",
    "coun1/len(cn_predict_1k), count2/len(cn_predict_1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence-transformer-roberta for WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_embeddings = candidates_embeddings(cn_test_1k, model_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = set()\n",
    "\n",
    "for line in lines:\n",
    "    relationships.add(line[1])\n",
    "    \n",
    "relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2sentence = {'/r/Antonym':\"is antonym for\", \n",
    "                 '/r/AtLocation': \"is located at\",\n",
    "                 '/r/CapableOf':\"is capable of\",\n",
    "                '/r/Causes':\"causes\",\n",
    "                '/r/CausesDesire':\"causes the desire of\",\n",
    "                '/r/CreatedBy':\"is created by\",\n",
    "                '/r/DefinedAs': \" is defined as\",\n",
    "                '/r/DerivedFrom': \"is derived from\",\n",
    "                '/r/Desires':\"desires\",\n",
    "                '/r/DistinctFrom':\"is distinct from\",\n",
    "                \"/r/Entails\":\"entails\",\n",
    "                '/r/EtymologicallyDerivedFrom':\"is etymologically derived from\",\n",
    "                '/r/EtymologicallyRelatedTo': \"is etymologically related to\",\n",
    "                '/r/FormOf':\"is form of\",\n",
    "                '/r/HasA': \"has a\",\n",
    "                '/r/HasContext': \"has the context of\",\n",
    "                '/r/HasFirstSubevent': \"has first subevent, \",\n",
    "                '/r/HasLastSubevent':\"has last subevent, \",\n",
    "                '/r/HasPrerequisite': \"has prerequisite, \",\n",
    "                '/r/HasProperty': \"has property, \",\n",
    "                '/r/HasSubevent': \"has subevent, \",\n",
    "                '/r/InstanceOf': \" is an instance of\",\n",
    "                '/r/IsA': \"is a\",\n",
    "                '/r/LocatedNear': \"is located nearby\",\n",
    "                '/r/MadeOf': \"is made of\",\n",
    "                '/r/MannerOf':\"has a manner of\",\n",
    "                '/r/MotivatedByGoal': \"is motivated by goal\",\n",
    "                '/r/NotCapableOf': \"is not capable of\",\n",
    "                '/r/NotDesires':\"does not desire\",\n",
    "                '/r/NotHasProperty':\"does not have property, \",\n",
    "                '/r/PartOf': \"is part of\",\n",
    "                '/r/ReceivesAction':\"receives the action, \",\n",
    "                '/r/RelatedTo':\"is related to\",\n",
    "                '/r/SimilarTo':\"is similar to\",\n",
    "                '/r/SymbolOf':\"is a symbol of\",\n",
    "                '/r/Synonym':\"is synonym for\",\n",
    "                '/r/UsedFor':\"is used for\",\n",
    "                '/r/dbpedia/capital': \"is the capital of\",\n",
    "                '/r/dbpedia/field':\" is the field of\",\n",
    "                '/r/dbpedia/genre':\"has genre,\",\n",
    "                '/r/dbpedia/genus':\"has genus, \",\n",
    "                '/r/dbpedia/influencedBy':\"is influenced by\",\n",
    "                '/r/dbpedia/knownFor': \"is known for\",\n",
    "                '/r/dbpedia/language':\"is the language \",\n",
    "                '/r/dbpedia/leader':\"has the leader, \",\n",
    "                '/r/dbpedia/occupation':\"has the occupation, \",\n",
    "                '/r/dbpedia/product':\"has the product, \"}\n",
    "\n",
    "cn_predict_1k = sentence_embedding(cn_test_1k, model = model_STR, label_embeddings = label_embeddings, word2sentence = word2sentence)\n",
    "write_prediction(cn_prediction_file, cn_predict_1k)\n",
    "coun1,coun2 = no_synset_count(cn_predict_1k)\n",
    "coun1/len(cn_predict_1k), count2/len(cn_predict_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distri = distribution(cn_test_1k)\n",
    "plt.hist(distri.values(),log=True,bins=30)\n",
    "print(\"mean ambiguity of label:\", sum(distri.values())/len(distri), \"size of records:\", len(cn_test_1k),\"num of distinct labels:\", len(distri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:isi]",
   "language": "python",
   "name": "conda-env-isi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
