{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_chunk(filename, n_each, n_total):\n",
    "    #n_each is the lines read for each time\n",
    "    #n_total, the total lines read for all\n",
    "\n",
    "    with open(filename, \"r\",encoding=\"UTF-8\") as f:\n",
    "        \"\"\"\n",
    "        load data\n",
    "        token is split by \"\\t\"\n",
    "        \"\"\"\n",
    "        head = f.readline().strip().split(\"\\t\")\n",
    "        lines = []\n",
    "\n",
    "        i = 0\n",
    "        total = 0\n",
    "        for line in f:\n",
    "            lines.append(line.strip().split(\"\\t\"))\n",
    "            \n",
    "            i+=1\n",
    "            total+=1\n",
    "\n",
    "            if i >= n_each:\n",
    "                yield head, lines\n",
    "                lines = []\n",
    "                i = 0\n",
    "\n",
    "            if total >= n_total:\n",
    "                break\n",
    "\n",
    "        yield head, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100 / 100  prob1: 0.31 prob2: 0.39\n",
      "running time: 11.900064468383789\n",
      " 100 / 100  prob1: 0.3125 prob2: 0.395\n",
      "running time: 20.85469889640808\n",
      " 100 / 100  prob1: 0.2816666666666667 prob2: 0.36333333333333334\n",
      "running time: 30.516653537750244\n",
      "  prob1: 0.2816666666666667 prob2: 0.36333333333333334\n",
      "running time: 30.518649339675903\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    read_file  = \"kgtk_conceptnet.tsv\"\n",
    "    write_file = \"./data/cn_predict.tsv\"\n",
    "    write_file_prob = \"./data/cn_missing_prob.tsv\"\n",
    "    write_file_freq = \"./data/cn_freq.tsv\"\n",
    "    n_each = 100\n",
    "    n_total = 300\n",
    "        \n",
    "    \n",
    "    #no synset label num\n",
    "    count1 = 0\n",
    "    #no synset triple num\n",
    "    count2 = 0\n",
    "    # current total counted lines\n",
    "    total_count = 0\n",
    "    \n",
    "    # initilization of file\n",
    "    with open(write_file, \"w\", newline='',encoding=\"UTF-8\") as f:\n",
    "        new_head = ['node1;label','relation','node2;label','node1','node2']\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(new_head)\n",
    "        \n",
    "    # initilization of file\n",
    "    with open(write_file_prob, \"w\", newline='',encoding=\"UTF-8\") as f:\n",
    "        f.write(\"prob1: prob of missing synsets for label, prob2: prob of missing synsets for triple\")\n",
    "        f.write(\"\\n\")\n",
    "    # initilization of file   \n",
    "    with open(write_file_freq, \"w\", newline='',encoding=\"UTF-8\") as f:\n",
    "        f.write(\"0,1,2 meaning the frequenct position of node_id. 0 meanns largest.-1 means no node_id\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    for head, lines in load_file_chunk(read_file, n_each, n_total):\n",
    "        cn_test = generate_gold_file(lines)\n",
    "        \n",
    "        label_embeddings = candidates_embeddings(cn_test, model_embedding)\n",
    "\n",
    "        cn_predict,freq = sentence_embedding(cn_test, label_embeddings = label_embeddings)\n",
    "        \n",
    "        write_prediction(write_file, cn_predict)\n",
    "        \n",
    "        temp1, temp2 = no_synset_count(cn_predict)\n",
    "        count1+=temp1\n",
    "        count2+= temp2\n",
    "        \n",
    "        total_count += len(cn_predict)\n",
    "        print(\"  prob1:\", count1/(2*total_count), \"prob2:\" , count2/total_count)\n",
    "        \n",
    "        # write probility into file\n",
    "        with open(write_file_prob, \"a\", newline='',encoding=\"UTF-8\") as f:\n",
    "            f.write(f\"prob1: {count1/(2*total_count)}, prob2: {count2/total_count}, total_count: {total_count}\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "        # write freq distribution into file\n",
    "        with open(write_file_freq, \"a\", newline='',encoding=\"UTF-8\") as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerows(freq)\n",
    "\n",
    "        \n",
    "        # release RAM\n",
    "        del cn_test, label_embeddings,temp1,temp2,cn_predict,f, lines, freq\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"running time:\", end- start)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:isi]",
   "language": "python",
   "name": "conda-env-isi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
