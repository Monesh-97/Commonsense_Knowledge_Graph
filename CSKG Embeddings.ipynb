{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSKG embeddings\n",
    "\n",
    "This notebook computes similarity between nodes in CSKG and performs grounding of questions/answers to CSKG.\n",
    "\n",
    "We will play with two different families of embeddings: graph and text embeddings.\n",
    "\n",
    "## Graph embeddings \n",
    "\n",
    "The graph embeddings have been computed by the command:\n",
    "\n",
    "`python embeddings/embedding_click.py -i input/kgtk_framenet.tsv -o output/kgtk_framenet`\n",
    "\n",
    "using the `embedding/embedding_click.py` script in this repository. This command invokes the Facebook PyBigGraph (PBG) library and computes graph embeddings with the ComplEx algorithm.\n",
    "\n",
    "We are currently integrating this function into the KGTK package, to make it more accessible to the AI community.\n",
    "\n",
    "## Text embeddings\n",
    "The text embeddings were computed by using the KGTK `text-embedding` command as follows:\n",
    "```\n",
    "kgtk text_embedding \\\n",
    "    --embedding-projector-metadata-path none \\\n",
    "    --label-properties \"label\" \\\n",
    "    --isa-properties \"/r/IsA\" \\\n",
    "    --description-properties \"/r/DefinedAs\" \\\n",
    "    --property-value \"/r/Causes\" \"/r/UsedFor\" \"/r/PartOf\" \"/r/AtLocation\" \"/r/CapableOf\" \\\n",
    "    \"/r/CausesDesire\" \"/r/SymbolOf\" \"/r/MadeOf\" \"/r/LocatedNear\" \"/r/Desires\" \"/r/HasProperty\" \"/r/HasFirstSubevent\" \\\n",
    "    \"/r/HasLastSubevent\" \"at:xAttr\" \"at:xEffect\" \"at:xIntent\" \"at:xNeed\" \"at:xReact\" \"at:xWant\" \\\n",
    "    --has-properties \"\" \\\n",
    "    -f kgtk_format \\\n",
    "    --output-data-format kgtk_format \\\n",
    "    --model bert-large-nli-cls-token \\\n",
    "    --save-embedding-sentence \\\n",
    "    -i sorted.tsv.gz \\\n",
    "    -p sorted.tsv.gz \\\n",
    "    > cskg_embedings.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "```\n",
    "conda create -n mowgli-env python=3.6 anaconda\n",
    "source activate mowgli-env\n",
    "\n",
    "cd grounding\n",
    "pip install -r requirements.txt\n",
    "conda install --yes faiss-cpu -c pytorch -n mowgli-env\n",
    "python -m spacy download en_core_web_lg\n",
    "conda install -c conda-forge python-annoy\n",
    "cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the embeddings - choose one of 100, 300, 400\n",
    "dim=100\n",
    "distance='angular'\n",
    "trees=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_filename='../output/embeddings/entity_embedding_%d.tsv' % dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = AnnoyIndex(dim, distance)  # Length of item vector that will be indexed\n",
    "node2id={}\n",
    "id2node={}\n",
    "with open(tsv_filename, 'r') as f:\n",
    "    i=0\n",
    "    for line in f:\n",
    "        node, *data=line.split()\n",
    "        v=[float(d) for d in data]\n",
    "        t.add_item(i, v)\n",
    "        node2id[node]=i\n",
    "        id2node[i]=node\n",
    "        i+=1\n",
    "t.build(trees) # number of trees (more -> higher precision at query time)\n",
    "t.save('complex_%d.ann' % dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = AnnoyIndex(dim, distance)\n",
    "u.load('complex_%d.ann' % dim) # super fast, will just mmap the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Most similar nodes in CSKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_similar_nodes(node, num_nodes=10):\n",
    "    node_id=node2id[node]\n",
    "    return [id2node[i] for i in u.get_nns_by_item(node_id, num_nodes+1)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/en/turtle ['/c/en/mock_turtle_soup/n', '/c/en/feeder_fish/n', '/c/en/freshwater', '/c/en/neckatee/n', '/c/en/big_cheeks', '/c/en/bockey/n', '/c/en/containing_things', '/c/en/catanadromous/a', '/c/en/downblouse/a', '/c/en/trebbiano/n'] \n",
      "\n",
      "/c/en/happy ['/c/en/happies/n', '/c/en/excited', '/c/en/people_who_enjoy_life', '/c/en/exultant/a', 'at:personx_feels_so_good', 'at:personx_finds_____to_play_with', '/c/en/gladsome/a', 'at:personx_makes_some_friends', 'at:personx_is_a_dream_come_true', 'at:personx_is_a_young_girl'] \n",
      "\n",
      "/c/en/turtle/n/wn/animal ['rg:en_carunculous', '/c/en/filmically/r', '/c/en/leroij', '/c/en/mata_mata_turtle/n', '/c/en/wide_bodied', '/c/en/surpassive', '/c/en/lepro', '/c/en/cognoscitive', '/c/en/run_red_light', 'at:gains_enemies'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes=['/c/en/turtle', '/c/en/happy', '/c/en/turtle/n/wn/animal']\n",
    "for node in nodes:\n",
    "    print(node, obtain_similar_nodes(node), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Compute similarity between two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1='/c/en/sailor'\n",
    "node2='/c/en/man'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3065621852874756"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.get_distance(node2id[node1], node2id[node2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Parsing questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grounding.graphify import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\n",
    "    'Max looked for the onions so that he could  make a stew.',\n",
    "    'To get the bathroom counters dry after washing your face, take a small hand lotion and wipe away the extra water around the sink.',\n",
    "    'To get the bathroom counters dry after washing your face, take a small hand towel and wipe away the extra water around the sink.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipilievski/opt/anaconda3/envs/mowgli-env/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/Users/filipilievski/opt/anaconda3/envs/mowgli-env/lib/python3.6/site-packages/allennlp/data/token_indexers/token_characters_indexer.py:56: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  UserWarning)\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]WARNING:allennlp.models.model:Encountered the antecedent_indices key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "parse_trees=parse.graphify_dataset(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Max looked for the onions so that he could  make a stew.\n",
      "Tokenized sentence ['Max', 'looked', 'for', 'the', 'onions', 'so', 'that', 'he', 'could', 'make', 'a', 'stew', '.']\n",
      "NODE1: looked RELATION ARG0 NODE2 Max\n",
      "NODE1: looked RELATION ARG1 NODE2 for the onions\n",
      "NODE1: looked RELATION ARGM-PRP NODE2 so that he could make a stew\n",
      "NODE1: make RELATION ARG0 NODE2 he\n",
      "NODE1: make RELATION ARGM-MOD NODE2 could\n",
      "NODE1: make RELATION ARG1 NODE2 a stew\n",
      "NODE1: so that he could make a stew RELATION sub NODE2 make\n",
      "NODE1: so that he could make a stew RELATION sub NODE2 he\n",
      "NODE1: so that he could make a stew RELATION sub NODE2 could\n",
      "NODE1: so that he could make a stew RELATION sub NODE2 a stew\n",
      "NODE1: Max RELATION coref NODE2 he\n",
      "\n",
      "Sentence: To get the bathroom counters dry after washing your face, take a small hand lotion and wipe away the extra water around the sink.\n",
      "Tokenized sentence ['To', 'get', 'the', 'bathroom', 'counters', 'dry', 'after', 'washing', 'your', 'face', ',', 'take', 'a', 'small', 'hand', 'lotion', 'and', 'wipe', 'away', 'the', 'extra', 'water', 'around', 'the', 'sink', '.']\n",
      "NODE1: washing RELATION ARG1 NODE2 your face\n",
      "NODE1: take RELATION ARGM-PRP NODE2 To get the bathroom counters dry after washing your face\n",
      "NODE1: take RELATION ARG1 NODE2 a small hand lotion\n",
      "NODE1: wipe RELATION ARGM-PRP NODE2 To get the bathroom counters dry after washing your face\n",
      "NODE1: wipe RELATION ARGM-DIR NODE2 away\n",
      "NODE1: wipe RELATION ARG1 NODE2 the extra water\n",
      "NODE1: wipe RELATION ARGM-LOC NODE2 around the sink\n",
      "NODE1: To get the bathroom counters dry after washing your face RELATION sub NODE2 washing\n",
      "NODE1: To get the bathroom counters dry after washing your face RELATION sub NODE2 your face\n",
      "\n",
      "Sentence: To get the bathroom counters dry after washing your face, take a small hand towel and wipe away the extra water around the sink.\n",
      "Tokenized sentence ['To', 'get', 'the', 'bathroom', 'counters', 'dry', 'after', 'washing', 'your', 'face', ',', 'take', 'a', 'small', 'hand', 'towel', 'and', 'wipe', 'away', 'the', 'extra', 'water', 'around', 'the', 'sink', '.']\n",
      "NODE1: washing RELATION ARG1 NODE2 your face\n",
      "NODE1: take RELATION ARGM-PRP NODE2 To get the bathroom counters dry after washing your face\n",
      "NODE1: take RELATION ARG1 NODE2 a small hand towel\n",
      "NODE1: wipe RELATION ARGM-PRP NODE2 To get the bathroom counters dry after washing your face\n",
      "NODE1: wipe RELATION ARGM-DIR NODE2 away\n",
      "NODE1: wipe RELATION ARG1 NODE2 the extra water\n",
      "NODE1: wipe RELATION ARGM-LOC NODE2 around the sink\n",
      "NODE1: To get the bathroom counters dry after washing your face RELATION sub NODE2 washing\n",
      "NODE1: To get the bathroom counters dry after washing your face RELATION sub NODE2 your face\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent_data in parse_trees:\n",
    "    print('Sentence:', sent_data['sentence'])\n",
    "    print('Tokenized sentence', sent_data['tokenized_sentence'])\n",
    "    \n",
    "    nodes={}\n",
    "    for n_id, n_data in sent_data['nodes'].items():\n",
    "        nodes[n_id]=n_data['phrase']\n",
    "    \n",
    "    for e_id, e_data in sent_data['edges'].items():\n",
    "        print('NODE1:', ' '.join(nodes[e_data['head_node_id']]), 'RELATION', e_data['edge_name'], 'NODE2', ' '.join(nodes[e_data['tail_node_id']]) )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Grounding questions and questions to ConceptNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grounding.graphify import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516782/516782 [00:37<00:00, 13925.21it/s]\n"
     ]
    }
   ],
   "source": [
    "linked_data=link.link(parse_trees, embedding_file='grounding/numberbatch-en-19.08.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Max looked for the onions so that he could  make a stew.\n",
      "Node phrase: ['looked']\n",
      "{'uri': '/c/en/give_glad_eye', 'score': 0.2498762607574463}\n",
      "{'uri': '/c/en/uplook', 'score': 0.2498762607574463}\n",
      "{'uri': '/c/en/look', 'score': 0.24307048320770264}\n",
      "{'uri': '/c/en/lookt', 'score': 0.1385062336921692}\n",
      "{'uri': '/c/en/looked', 'score': -1.0967254638671875e-05}\n",
      "\n",
      "Node phrase: ['Max']\n",
      "{'uri': '/c/en/maxy', 'score': 0.2219405174255371}\n",
      "{'uri': '/c/en/maxie', 'score': 0.2098349928855896}\n",
      "{'uri': '/c/en/maxine', 'score': 0.19799458980560303}\n",
      "{'uri': '/c/en/maximus', 'score': 0.1656038761138916}\n",
      "{'uri': '/c/en/max', 'score': 2.1219253540039062e-05}\n",
      "\n",
      "Node phrase: ['for', 'the', 'onions']\n",
      "{'uri': '/c/en/vidalia_onion', 'score': 0.11641442775726318}\n",
      "{'uri': '/c/en/onion', 'score': 0.10344946384429932}\n",
      "{'uri': '/c/en/ingredient_in_salsa', 'score': 0.09622251987457275}\n",
      "{'uri': '/c/en/onions', 'score': 8.165836334228516e-05}\n",
      "{'uri': '/c/en/for', 'score': 2.2649765014648438e-06}\n",
      "\n",
      "Node phrase: ['so', 'that', 'he', 'could', 'make', 'a', 'stew']\n",
      "{'uri': '/c/en/make', 'score': 3.3736228942871094e-05}\n",
      "{'uri': '/c/en/so_that', 'score': 2.2113323211669922e-05}\n",
      "{'uri': '/c/en/he', 'score': 9.179115295410156e-06}\n",
      "{'uri': '/c/en/could', 'score': -2.9921531677246094e-05}\n",
      "{'uri': '/c/en/stew', 'score': -8.463859558105469e-05}\n",
      "\n",
      "Node phrase: ['make']\n",
      "{'uri': '/c/en/foremake', 'score': 0.18033039569854736}\n",
      "{'uri': '/c/en/maketh', 'score': 0.1189420223236084}\n",
      "{'uri': '/c/en/makest', 'score': 0.07135224342346191}\n",
      "{'uri': '/c/en/film_make', 'score': 0.005058348178863525}\n",
      "{'uri': '/c/en/make', 'score': 3.3736228942871094e-05}\n",
      "\n",
      "Node phrase: ['he']\n",
      "{'uri': \"/c/en/he's\", 'score': 0.1669536828994751}\n",
      "{'uri': '/c/en/she', 'score': 0.15240478515625}\n",
      "{'uri': '/c/en/he_or_she', 'score': 0.11238044500350952}\n",
      "{'uri': '/c/en/s_he', 'score': 0.09848588705062866}\n",
      "{'uri': '/c/en/he', 'score': 9.179115295410156e-06}\n",
      "\n",
      "Node phrase: ['could']\n",
      "{'uri': '/c/en/would', 'score': 0.12528467178344727}\n",
      "{'uri': '/c/en/couldn’t', 'score': 0.07447981834411621}\n",
      "{'uri': '/c/en/couldst', 'score': 0.06240642070770264}\n",
      "{'uri': \"/c/en/couldn't\", 'score': 0.05818939208984375}\n",
      "{'uri': '/c/en/could', 'score': -2.9921531677246094e-05}\n",
      "\n",
      "Node phrase: ['a', 'stew']\n",
      "{'uri': '/c/en/stews', 'score': 0.0810580849647522}\n",
      "{'uri': '/c/en/stewy', 'score': 0.05264413356781006}\n",
      "{'uri': '/c/en/lobster_stew', 'score': 0.010990381240844727}\n",
      "{'uri': '/c/en/oyster_stew', 'score': 0.008328914642333984}\n",
      "{'uri': '/c/en/stew', 'score': -8.463859558105469e-05}\n",
      "\n",
      "\n",
      "Sentence: To get the bathroom counters dry after washing your face, take a small hand lotion and wipe away the extra water around the sink.\n",
      "Node phrase: ['washing']\n",
      "{'uri': '/c/en/having_clean_clothes', 'score': 0.12734758853912354}\n",
      "{'uri': '/c/en/car_washing', 'score': 0.11475837230682373}\n",
      "{'uri': '/c/en/lavagate', 'score': 0.10997474193572998}\n",
      "{'uri': '/c/en/do_laundry', 'score': 0.09733724594116211}\n",
      "{'uri': '/c/en/washing', 'score': 9.232759475708008e-05}\n",
      "\n",
      "Node phrase: ['your', 'face']\n",
      "{'uri': '/c/en/faceful', 'score': 0.03737354278564453}\n",
      "{'uri': '/c/en/faceable', 'score': 0.014332175254821777}\n",
      "{'uri': '/c/en/nonface', 'score': 0.0027320384979248047}\n",
      "{'uri': '/c/en/face', 'score': -3.254413604736328e-05}\n",
      "{'uri': '/c/en/your', 'score': -7.891654968261719e-05}\n",
      "\n",
      "Node phrase: ['take']\n",
      "{'uri': '/c/en/arreption', 'score': 0.19794702529907227}\n",
      "{'uri': '/c/en/takeable', 'score': 0.10872077941894531}\n",
      "{'uri': '/c/en/takes', 'score': 0.10642451047897339}\n",
      "{'uri': '/c/en/takest', 'score': 0.06000673770904541}\n",
      "{'uri': '/c/en/take', 'score': 6.306171417236328e-05}\n",
      "\n",
      "Node phrase: ['To', 'get', 'the', 'bathroom', 'counters', 'dry', 'after', 'washing', 'your', 'face']\n",
      "{'uri': '/c/en/bathroom', 'score': 8.225440979003906e-06}\n",
      "{'uri': '/c/en/face', 'score': -3.254413604736328e-05}\n",
      "{'uri': '/c/en/get', 'score': -3.707408905029297e-05}\n",
      "{'uri': '/c/en/your', 'score': -7.891654968261719e-05}\n",
      "{'uri': '/c/en/dry', 'score': -0.00014138221740722656}\n",
      "\n",
      "Node phrase: ['a', 'small', 'hand', 'lotion']\n",
      "{'uri': '/c/en/body_lotion', 'score': 0.06785374879837036}\n",
      "{'uri': '/c/en/lotional', 'score': 0.0674670934677124}\n",
      "{'uri': '/c/en/supersmall', 'score': 0.03388255834579468}\n",
      "{'uri': '/c/en/hand_lotion', 'score': 3.314018249511719e-05}\n",
      "{'uri': '/c/en/small', 'score': -1.6450881958007812e-05}\n",
      "\n",
      "Node phrase: ['wipe']\n",
      "{'uri': '/c/en/wipeable', 'score': 0.05955857038497925}\n",
      "{'uri': '/c/en/wipes', 'score': 0.05914294719696045}\n",
      "{'uri': '/c/en/overwipe', 'score': 0.003169119358062744}\n",
      "{'uri': '/c/en/rewipe', 'score': 0.003169119358062744}\n",
      "{'uri': '/c/en/wipe', 'score': -4.076957702636719e-05}\n",
      "\n",
      "Node phrase: ['away']\n",
      "{'uri': '/c/en/far_apart', 'score': 0.004051148891448975}\n",
      "{'uri': '/c/en/relative_position', 'score': 0.004051148891448975}\n",
      "{'uri': \"/c/en/when_cat's_away\", 'score': 0.004051148891448975}\n",
      "{'uri': '/c/en/give_away_shop', 'score': 0.004051148891448975}\n",
      "{'uri': '/c/en/away', 'score': 2.6524066925048828e-05}\n",
      "\n",
      "Node phrase: ['the', 'extra', 'water']\n",
      "{'uri': '/c/en/waterward', 'score': 0.003735780715942383}\n",
      "{'uri': '/c/en/hydrogen_and_oxygen', 'score': 0.003735780715942383}\n",
      "{'uri': '/c/en/extraness', 'score': 0.0033884048461914062}\n",
      "{'uri': '/c/en/water', 'score': 2.9921531677246094e-05}\n",
      "{'uri': '/c/en/extra', 'score': -1.1920928955078125e-07}\n",
      "\n",
      "Node phrase: ['around', 'the', 'sink']\n",
      "{'uri': '/c/en/sench', 'score': 0.03055506944656372}\n",
      "{'uri': '/c/en/sinkful', 'score': 0.019317626953125}\n",
      "{'uri': '/c/en/in_circles', 'score': 0.003506481647491455}\n",
      "{'uri': '/c/en/around', 'score': 1.055002212524414e-05}\n",
      "{'uri': '/c/en/sink', 'score': -3.7670135498046875e-05}\n",
      "\n",
      "\n",
      "Sentence: To get the bathroom counters dry after washing your face, take a small hand towel and wipe away the extra water around the sink.\n",
      "Node phrase: ['washing']\n",
      "{'uri': '/c/en/having_clean_clothes', 'score': 0.12734758853912354}\n",
      "{'uri': '/c/en/car_washing', 'score': 0.11475837230682373}\n",
      "{'uri': '/c/en/lavagate', 'score': 0.10997474193572998}\n",
      "{'uri': '/c/en/do_laundry', 'score': 0.09733724594116211}\n",
      "{'uri': '/c/en/washing', 'score': 9.232759475708008e-05}\n",
      "\n",
      "Node phrase: ['your', 'face']\n",
      "{'uri': '/c/en/faceful', 'score': 0.03737354278564453}\n",
      "{'uri': '/c/en/faceable', 'score': 0.014332175254821777}\n",
      "{'uri': '/c/en/nonface', 'score': 0.0027320384979248047}\n",
      "{'uri': '/c/en/face', 'score': -3.254413604736328e-05}\n",
      "{'uri': '/c/en/your', 'score': -7.891654968261719e-05}\n",
      "\n",
      "Node phrase: ['take']\n",
      "{'uri': '/c/en/arreption', 'score': 0.19794702529907227}\n",
      "{'uri': '/c/en/takeable', 'score': 0.10872077941894531}\n",
      "{'uri': '/c/en/takes', 'score': 0.10642451047897339}\n",
      "{'uri': '/c/en/takest', 'score': 0.06000673770904541}\n",
      "{'uri': '/c/en/take', 'score': 6.306171417236328e-05}\n",
      "\n",
      "Node phrase: ['To', 'get', 'the', 'bathroom', 'counters', 'dry', 'after', 'washing', 'your', 'face']\n",
      "{'uri': '/c/en/bathroom', 'score': 8.225440979003906e-06}\n",
      "{'uri': '/c/en/face', 'score': -3.254413604736328e-05}\n",
      "{'uri': '/c/en/get', 'score': -3.707408905029297e-05}\n",
      "{'uri': '/c/en/your', 'score': -7.891654968261719e-05}\n",
      "{'uri': '/c/en/dry', 'score': -0.00014138221740722656}\n",
      "\n",
      "Node phrase: ['a', 'small', 'hand', 'towel']\n",
      "{'uri': '/c/en/towel', 'score': 0.04950082302093506}\n",
      "{'uri': '/c/en/supersmall', 'score': 0.03388255834579468}\n",
      "{'uri': '/c/en/face_towel', 'score': 0.00377655029296875}\n",
      "{'uri': '/c/en/hand_towel', 'score': 3.725290298461914e-05}\n",
      "{'uri': '/c/en/small', 'score': -1.6450881958007812e-05}\n",
      "\n",
      "Node phrase: ['wipe']\n",
      "{'uri': '/c/en/wipeable', 'score': 0.05955857038497925}\n",
      "{'uri': '/c/en/wipes', 'score': 0.05914294719696045}\n",
      "{'uri': '/c/en/overwipe', 'score': 0.003169119358062744}\n",
      "{'uri': '/c/en/rewipe', 'score': 0.003169119358062744}\n",
      "{'uri': '/c/en/wipe', 'score': -4.076957702636719e-05}\n",
      "\n",
      "Node phrase: ['away']\n",
      "{'uri': '/c/en/far_apart', 'score': 0.004051148891448975}\n",
      "{'uri': '/c/en/relative_position', 'score': 0.004051148891448975}\n",
      "{'uri': \"/c/en/when_cat's_away\", 'score': 0.004051148891448975}\n",
      "{'uri': '/c/en/give_away_shop', 'score': 0.004051148891448975}\n",
      "{'uri': '/c/en/away', 'score': 2.6524066925048828e-05}\n",
      "\n",
      "Node phrase: ['the', 'extra', 'water']\n",
      "{'uri': '/c/en/waterward', 'score': 0.003735780715942383}\n",
      "{'uri': '/c/en/hydrogen_and_oxygen', 'score': 0.003735780715942383}\n",
      "{'uri': '/c/en/extraness', 'score': 0.0033884048461914062}\n",
      "{'uri': '/c/en/water', 'score': 2.9921531677246094e-05}\n",
      "{'uri': '/c/en/extra', 'score': -1.1920928955078125e-07}\n",
      "\n",
      "Node phrase: ['around', 'the', 'sink']\n",
      "{'uri': '/c/en/sench', 'score': 0.03055506944656372}\n",
      "{'uri': '/c/en/sinkful', 'score': 0.019317626953125}\n",
      "{'uri': '/c/en/in_circles', 'score': 0.003506481647491455}\n",
      "{'uri': '/c/en/around', 'score': 1.055002212524414e-05}\n",
      "{'uri': '/c/en/sink', 'score': -3.7670135498046875e-05}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent_data in linked_data:\n",
    "    print('Sentence:', sent_data['sentence'])\n",
    "    for n_id, n_data in sent_data['nodes'].items():\n",
    "        print('Node phrase:', n_data['phrase'])\n",
    "        for c in reversed(n_data['candidates']):\n",
    "            print(c)\n",
    "        print()\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
